{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e715612a-77ac-46a5-88a5-9c251704fa59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "4.4 Saving Processed Data to Azure SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c4751f-2cb4-47ed-b646-64760edc8d5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27919f3e-a9d8-439e-a688-804562bbda36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "    4.4.1. Spliting the cleaned&transformed data into fact&dim tables:\n",
    "        Fact Table: Order Items with calculated columns.\n",
    "        Dimension Tables: Customers, Products, Sellers, Date.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "008b50e9-7c26-4784-8843-a07e09f3afd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#reading cleaned & merged datasets\n",
    "order_items_data_cleaned = pd.read_csv('order_items_data_cleaned.csv')\n",
    "orders_customers_data_cleaned = pd.read_csv('orders_customers_data_cleaned.csv')\n",
    "products_data_cleaned = pd.read_csv('products_data_cleaned.csv')\n",
    "order_payments_data_cleaned = pd.read_csv('order_payments_data_cleaned.csv')\n",
    "customers_data_cleaned = pd.read_csv('customers_data_cleaned.csv')\n",
    "sellers_data_cleaned = pd.read_csv('sellers_data_cleaned.csv')\n",
    "geolocation_data_cleaned = pd.read_csv('geolocation_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f30f1f5-4b88-4bab-90c7-1e3ac3fb7515",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1. Fact Table Order Items with calculated columns (already done): order_items_data_cleaned\n",
    "\n",
    "#2. Customers dim table\n",
    "# checking data types are the same before merging\n",
    "customers_data_cleaned['customer_zip_code_prefix'] = customers_data_cleaned['customer_zip_code_prefix'].astype(str)\n",
    "geolocation_data_cleaned['geolocation_zip_code_prefix'] = geolocation_data_cleaned['geolocation_zip_code_prefix'].astype(str)\n",
    "\n",
    "# dropping duplicates in geolocation data for merging\n",
    "geolocation_data_cleaned = geolocation_data_cleaned.drop_duplicates(subset=['geolocation_zip_code_prefix'])\n",
    "\n",
    "# merging geolocation data with customers to include geographic information\n",
    "customers_data_cleaned = customers_data_cleaned.merge(\n",
    "    geolocation_data_cleaned,\n",
    "    left_on='customer_zip_code_prefix',\n",
    "    right_on='geolocation_zip_code_prefix',\n",
    "    how='left',\n",
    "    suffixes=('', '_geo')\n",
    ")\n",
    "\n",
    "#3. Sellers dim table\n",
    "# checking data type match\n",
    "sellers_data_cleaned['seller_zip_code_prefix'] = sellers_data_cleaned['seller_zip_code_prefix'].astype(str)\n",
    "\n",
    "# merging geolocation data with sellers to include geographic information\n",
    "sellers_data_cleaned = sellers_data_cleaned.merge(\n",
    "    geolocation_data_cleaned,\n",
    "    left_on='seller_zip_code_prefix',\n",
    "    right_on='geolocation_zip_code_prefix',\n",
    "    how='left',\n",
    "    suffixes=('', '_geo')\n",
    ")\n",
    "\n",
    "#4. Products dim table (already done): products_data_cleaned\n",
    "#5. Orders customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2362469-72c3-47b0-b0f4-382cd664d5a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/5062/command-2363904231686343-2560332324:2: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n  customers_data_cleaned['effective_date'] = pd.to_datetime('now')\n/root/.ipykernel/5062/command-2363904231686343-2560332324:5: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n  products_data_cleaned['effective_date'] = pd.to_datetime('now')\n/root/.ipykernel/5062/command-2363904231686343-2560332324:8: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n  sellers_data_cleaned['effective_date'] = pd.to_datetime('now')\n/root/.ipykernel/5062/command-2363904231686343-2560332324:11: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n  order_items_data_cleaned['effective_date'] = pd.to_datetime('now')\n"
     ]
    }
   ],
   "source": [
    "#adding effective and end dates to track historical changes in the data\n",
    "customers_data_cleaned['effective_date'] = pd.to_datetime('now')\n",
    "customers_data_cleaned['end_date'] = pd.NaT\n",
    "\n",
    "products_data_cleaned['effective_date'] = pd.to_datetime('now')\n",
    "products_data_cleaned['end_date'] = pd.NaT\n",
    "\n",
    "sellers_data_cleaned['effective_date'] = pd.to_datetime('now')\n",
    "sellers_data_cleaned['end_date'] = pd.NaT\n",
    "\n",
    "order_items_data_cleaned['effective_date'] = pd.to_datetime('now')\n",
    "order_items_data_cleaned['end_date'] = pd.NaT\n",
    "\n",
    "order_customers_data_cleaned['effective_date'] = pd.to_datetime('now')\n",
    "order_customers_data_cleaned['end_date'] = pd.NaT\n",
    "\n",
    "#creating a date dimension table from the orders and customers data\n",
    "date_dim = orders_customers_data_cleaned[\n",
    "    ['order_purchase_timestamp', 'order_estimated_delivery_date']\n",
    "].drop_duplicates().reset_index(drop=True)\n",
    "#renaming columns for clarity\n",
    "date_dim.rename(\n",
    "    columns={\n",
    "        'order_purchase_timestamp': 'purchase_date', \n",
    "        'order_estimated_delivery_date': 'estimated_delivery_date'\n",
    "    }, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b291c76-08a4-4371-809f-b0429c40cf14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#constructing the JDBC URL and connection properties for connecting to the Azure SQL Database.\n",
    "\n",
    "from msal import ConfidentialClientApplication\n",
    "\n",
    "tenant_id = 'xxxx'  #tenantID\n",
    "client_id = 'xxxx'  #clientID\n",
    "client_secret = 'xxxx' #secret value generated during App Registration\n",
    "\n",
    "# Azure SQL Server details\n",
    "jdbcHostname = \"test-server-2.database.windows.net\"\n",
    "jdbcDatabase = \"olist_db\"\n",
    "jdbcPort = 1433\n",
    "\n",
    "# Get the Access Token from Azure AD\n",
    "authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n",
    "app = ConfidentialClientApplication(client_id, authority=authority, client_credential=client_secret)\n",
    "\n",
    "token_response = app.acquire_token_for_client(scopes=[\"https://database.windows.net/.default\"])\n",
    "access_token = token_response.get('access_token')\n",
    "\n",
    "if not access_token:\n",
    "    raise Exception(\"Failed to acquire access token.\")\n",
    "\n",
    "# Construct the JDBC URL\n",
    "jdbcUrl = f\"jdbc:sqlserver://{jdbcHostname}:{jdbcPort};database={jdbcDatabase};encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "\n",
    "# Connection properties for the JDBC driver\n",
    "connectionProperties = {\n",
    "    \"accessToken\": access_token,\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "147615de-0a8a-46aa-823e-2e70a48a025b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to Azure SQL Database!\n"
     ]
    }
   ],
   "source": [
    "# Convert Pandas DataFrames to Spark DataFrames\n",
    "customers_spark_df = spark.createDataFrame(customers_data_cleaned)\n",
    "products_spark_df = spark.createDataFrame(products_data_cleaned)\n",
    "sellers_spark_df = spark.createDataFrame(sellers_data_cleaned)\n",
    "date_dim_spark_df = spark.createDataFrame(date_dim)\n",
    "order_items_spark_df = spark.createDataFrame(order_items_data_cleaned)\n",
    "\n",
    "# Write the Spark DataFrames to Azure SQL Database\n",
    "customers_spark_df.write.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"dim_customers\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connectionProperties\n",
    ")\n",
    "\n",
    "products_spark_df.write.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"dim_products\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connectionProperties\n",
    ")\n",
    "\n",
    "sellers_spark_df.write.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"dim_sellers\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connectionProperties\n",
    ")\n",
    "\n",
    "date_dim_spark_df.write.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"dim_date\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connectionProperties\n",
    ")\n",
    "\n",
    "order_items_spark_df.write.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"fact_order_items\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connectionProperties\n",
    ")\n",
    "\n",
    "print(\"Data successfully written to Azure SQL Database!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba32041e-adef-4448-8870-587f521d350b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nBefore SCD Type 1 Update:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_id</th><th>customer_unique_id</th><th>customer_zip_code_prefix</th><th>customer_city</th><th>customer_state</th><th>geolocation_zip_code_prefix</th><th>geolocation_lat</th><th>geolocation_lng</th><th>geolocation_city</th><th>geolocation_state</th><th>effective_date</th><th>end_date</th></tr></thead><tbody><tr><td>69ad55d4bfffc89d50f84aa4e3648d5e</td><td>8ea8b926af8086a391b130944d230549</td><td>92310</td><td>Canoas</td><td>RS</td><td>92310</td><td>-29.915258224808355</td><td>-51.18616902904408</td><td>Canoas</td><td>RS</td><td>2024-10-04T17:40:48.273131Z</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "69ad55d4bfffc89d50f84aa4e3648d5e",
         "8ea8b926af8086a391b130944d230549",
         "92310",
         "Canoas",
         "RS",
         "92310",
         -29.915258224808355,
         -51.18616902904408,
         "Canoas",
         "RS",
         "2024-10-04T17:40:48.273131Z",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_unique_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_zip_code_prefix",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_zip_code_prefix",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_lat",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_lng",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "effective_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "end_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nAfter SCD Type 1 Update:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>customer_id</th><th>customer_unique_id</th><th>customer_zip_code_prefix</th><th>customer_city</th><th>customer_state</th><th>geolocation_zip_code_prefix</th><th>geolocation_lat</th><th>geolocation_lng</th><th>geolocation_city</th><th>geolocation_state</th><th>effective_date</th><th>end_date</th></tr></thead><tbody><tr><td>69ad55d4bfffc89d50f84aa4e3648d5e</td><td>8ea8b926af8086a391b130944d230549</td><td>92310</td><td>Curitiba</td><td>PR</td><td>92310</td><td>-29.915258224808355</td><td>-51.18616902904408</td><td>Canoas</td><td>RS</td><td>2024-10-04T17:40:48.273131Z</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "69ad55d4bfffc89d50f84aa4e3648d5e",
         "8ea8b926af8086a391b130944d230549",
         "92310",
         "Curitiba",
         "PR",
         "92310",
         -29.915258224808355,
         -51.18616902904408,
         "Canoas",
         "RS",
         "2024-10-04T17:40:48.273131Z",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_unique_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_zip_code_prefix",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "customer_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_zip_code_prefix",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_lat",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_lng",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "geolocation_state",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "effective_date",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "end_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Implementing SCD Type 1\n",
    "\n",
    "#1. SCD Type 1 - performed on customers_data_cleaned; update customer city and state directly, overwriting previous values\n",
    "def scd_type_1_update(customers_spark_df, customer_id, updated_data):\n",
    "    print(\"\\nBefore SCD Type 1 Update:\")\n",
    "    display(customers_spark_df.filter(customers_spark_df['customer_id'] == customer_id))\n",
    "    \n",
    "    for key, value in updated_data.items():\n",
    "        customers_spark_df = customers_spark_df.withColumn(\n",
    "            key, \n",
    "            F.when(customers_spark_df['customer_id'] == customer_id, value).otherwise(customers_spark_df[key])\n",
    "        )\n",
    "    \n",
    "    print(\"\\nAfter SCD Type 1 Update:\")\n",
    "    display(customers_spark_df.filter(customers_spark_df['customer_id'] == customer_id))\n",
    "    \n",
    "    return customers_spark_df\n",
    "\n",
    "# Changing one record\n",
    "updated_data_scd1 = {'customer_city': 'Curitiba', 'customer_state': 'PR'}\n",
    "customers_spark_df = scd_type_1_update(customers_spark_df, '69ad55d4bfffc89d50f84aa4e3648d5e', updated_data_scd1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c9de065-da7d-4390-bbbc-cff256544e0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# writing the updated Spark DataFrame to Azure SQL Database\n",
    "customers_spark_df.write.jdbc(\n",
    "    url=jdbcUrl,\n",
    "    table=\"dim_customers2\",\n",
    "    mode=\"overwrite\",\n",
    "    properties=connectionProperties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "087b0761-01b3-4b79-9a72-9b0e7f978c0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c21e8b1-e696-4b5a-a28b-6ff3ffc3a519",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.4 Saving Processed Data to SQL Server (Fact & Dimension Tables)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
